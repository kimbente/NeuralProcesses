{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Processes\n",
    "\n",
    "Implementation of Neural Processes in PyTorch\n",
    "\n",
    "# Overview\n",
    "\n",
    "1. Data Generator\n",
    "2. Plotting function\n",
    "3. Encoder \n",
    "4. Decoder\n",
    "5. Model\n",
    "\n",
    "# To Do\n",
    "\n",
    "- [ ] Docstrings\n",
    "- [ ] Inline comments\n",
    "- [ ] Visualisation of testing and training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import watermark\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "watermark : 2.3.1\n",
      "numpy     : 1.23.5\n",
      "matplotlib: 3.6.3\n",
      "torch     : 1.13.1\n",
      "\n",
      "Last updated: 2023-05-03T14:05:56.275214+10:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.16\n",
      "IPython version      : 8.10.0\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 22.3.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "# Versions for reproducibility\n",
    "%watermark --iversions\n",
    "%watermark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "- using collections from namedtuple\n",
    "- - start with generate curved function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The (A)NP takes as input a `NPRegressionDescription` namedtuple with fields:\n",
    "#   `query`: a tuple containing ((context_x, context_y), target_x)\n",
    "#   `target_y`: a tensor containing the ground truth for the targets to be\n",
    "#     predicted\n",
    "#   `num_total_points`: A vector containing a scalar that describes the total\n",
    "#     number of datapoints used (context + target)\n",
    "#   `num_context_points`: A vector containing a scalar that describes the number\n",
    "#     of datapoints used as context\n",
    "# The GPCurvesReader returns the newly sampled data in this format at each\n",
    "# iteration\n",
    "\n",
    "NPRegressionDescription = collections.namedtuple(\n",
    "    \"NPRegressionDescription\",\n",
    "    (\"query\", \"target_y\", \"num_total_points\", \"num_context_points\"))\n",
    "\n",
    "\n",
    "class GPCurvesReader(object):\n",
    "  \"\"\"Generates curves using a Gaussian Process (GP).\n",
    "\n",
    "  Supports vector inputs (x) and vector outputs (y). Kernel is\n",
    "  mean-squared exponential, using the x-value l2 coordinate distance scaled by\n",
    "  some factor chosen randomly in a range. Outputs are independent gaussian\n",
    "  processes.\n",
    "\n",
    "  Functions:\n",
    "  _gaussian_kernel()\n",
    "  generate_curves()\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               batch_size,\n",
    "               max_num_context,\n",
    "               x_size = 1,\n",
    "               y_size = 1,\n",
    "               l1_scale = 0.6,\n",
    "               sigma_scale = 1.0,\n",
    "               random_kernel_parameters = True,\n",
    "               testing = False):\n",
    "    \"\"\"Creates a regression dataset of functions sampled from a GP.\n",
    "\n",
    "    Args:\n",
    "      batch_size: An integer.\n",
    "      max_num_context: The max number of observations in the context.\n",
    "      x_size: Integer >= 1 for length of \"x values\" vector.\n",
    "      y_size: Integer >= 1 for length of \"y values\" vector.\n",
    "      l1_scale: Float; typical scale for kernel distance function.\n",
    "      sigma_scale: Float; typical scale for variance.\n",
    "      random_kernel_parameters: If `True`, the kernel parameters (l1 and sigma) \n",
    "          will be sampled uniformly within [0.1, l1_scale] and [0.1, sigma_scale].\n",
    "      testing: Boolean that indicates whether we are testing. If so there are\n",
    "          more targets for visualization.\n",
    "    \"\"\"\n",
    "    self._batch_size = batch_size\n",
    "    self._max_num_context = max_num_context\n",
    "    self._x_size = x_size\n",
    "    self._y_size = y_size\n",
    "    self._l1_scale = l1_scale\n",
    "    self._sigma_scale = sigma_scale\n",
    "    self._random_kernel_parameters = random_kernel_parameters\n",
    "    self._testing = testing\n",
    "\n",
    "  # _ in function name indicate internal use\n",
    "  def _gaussian_kernel(self, xdata, l1, sigma_f, sigma_noise = 2e-2):\n",
    "    \"\"\"Applies the Gaussian kernel to generate curve data. generate_curved() calls this function\n",
    "\n",
    "    Args:\n",
    "      xdata: Tensor of shape [B, num_total_points, x_size] with\n",
    "          the values of the x-axis data.\n",
    "      l1: Tensor of shape [B, y_size, x_size], the scale\n",
    "          parameter of the Gaussian kernel.\n",
    "      sigma_f: Tensor of shape [B, y_size], the magnitude\n",
    "          of the std.\n",
    "      sigma_noise: Float, std of the noise that we add for stability.\n",
    "\n",
    "    Returns:\n",
    "      The kernel, a float tensor of shape\n",
    "      [B, y_size, num_total_points, num_total_points].\n",
    "    \"\"\"\n",
    "    # Extract second dim (dim 1)\n",
    "    num_total_points = xdata.size(dim = 1)\n",
    "\n",
    "    # Expand and take the difference\n",
    "    xdata1 = torch.unsqueeze(xdata, dim = 1) # [B, 1, num_total_points, x_size]\n",
    "    xdata2 = torch.unsqueeze(xdata, dim = 2) # [B, num_total_points, 1, x_size]\n",
    "    diff = xdata1 - xdata2  # [B, num_total_points, num_total_points, x_size]\n",
    "\n",
    "    # [B, y_size, num_total_points, num_total_points, x_size]\n",
    "    # Square scaled difference\n",
    "    norm = torch.square(diff[:, None, :, :, :] / l1[:, :, None, None, :])\n",
    "\n",
    "    # Reduce along last dimension: x_size\n",
    "    norm = torch.sum(norm, axis = -1) # [B, y_size, num_total_points, num_total_points]\n",
    "\n",
    "    # [B, y_size, num_total_points, num_total_points]\n",
    "    kernel = torch.square(sigma_f)[:, :, None, None] * torch.exp(- 0.5 * norm)\n",
    "\n",
    "    # Add some noise to the diagonal to make the cholesky work.\n",
    "    kernel += (sigma_noise ** 2) * torch.eye(num_total_points)\n",
    "\n",
    "    return kernel\n",
    "\n",
    "  def generate_curves(self):\n",
    "    \"\"\"Builds the op delivering the data.\n",
    "\n",
    "    Generated functions are `float32` with x values between -2 and 2.\n",
    "    \n",
    "    Returns:\n",
    "      A `NPRegressionDescription` namedtuple.\n",
    "    \"\"\"\n",
    "    num_context = torch.randint(low = 3, high = self._max_num_context, size = [], dtype = torch.int32)\n",
    "\n",
    "    # If we are TESTING we want to have more targets and have them evenly distributed in order to plot the function.\n",
    "    if self._testing:\n",
    "      # targets only\n",
    "      num_target = 400\n",
    "      num_total_points = num_target\n",
    "      \n",
    "      # torch.range includes end value.\n",
    "      x_range = torch.arange(start = -2., end = 2, step = 1./100, dtype = torch.float32)\n",
    "      # repeat for each batch\n",
    "      x_tiles = torch.tile(input = x_range, dims = (self._batch_size, 1))\n",
    "      # Unsqueeze to create explicit last dim \n",
    "      x_values = torch.unsqueeze(x_tiles, dim = -1)\n",
    "    \n",
    "    # During TRAINING the number of target points and their x-positions are selected at random\n",
    "    else:\n",
    "      # Set number of target points by uniformly sampling a random integer\n",
    "      num_target = torch.randint(low = 3, high = (self._max_num_context - num_context), size = [], dtype = torch.int32)\n",
    "      num_total_points = num_context + num_target\n",
    "      # Uniformly sample random floats as x and scale between [-2, 2]\n",
    "      x_values = ((torch.rand(size = (self._batch_size, num_total_points, self._x_size)) * 4) - 2)\n",
    "\n",
    "    # Set kernel parameters\n",
    "    # Either choose a set of random parameters for the mini-batch\n",
    "    if self._random_kernel_parameters:\n",
    "      # Scale [0, 1] outputs by range and Shift by bias\n",
    "      l1 = ((torch.rand(size = (self._batch_size, self._y_size, self._x_size)) * (self._l1_scale - 0.1)) + 0.1)\n",
    "      # Scale [0, 1] outputs by range and Shift by bias\n",
    "      # No noise in x \n",
    "      sigma_f = ((torch.rand(size = (self._batch_size, self._y_size)) * (self._sigma_scale - 0.1)) + 0.1)\n",
    "    \n",
    "    # Or use the same fixed parameters for all mini-batches\n",
    "    else:\n",
    "      l1 = torch.ones(size = (self._batch_size, self._y_size, self._x_size)) * self._l1_scale\n",
    "      sigma_f = torch.ones(size = (self._batch_size, self._y_size)) * self._sigma_scale\n",
    "\n",
    "    # Pass the x_values through the Gaussian kernel\n",
    "    # [batch_size, y_size, num_total_points, num_total_points]\n",
    "    kernel = self._gaussian_kernel(x_values, l1, sigma_f)\n",
    "\n",
    "    # Calculate Cholesky, using double precision for better stability:\n",
    "    cholesky = torch.linalg.cholesky(kernel.type(torch.DoubleTensor)).type(torch.FloatTensor)\n",
    "\n",
    "    y_values = torch.matmul(cholesky, torch.randn(size = (self._batch_size, self._y_size, num_total_points, 1)))\n",
    "\n",
    "    # Sample a curve\n",
    "    # [batch_size, y_size, num_total_points, 1]\n",
    "    y_values = torch.matmul(cholesky, torch.randn(size = (self._batch_size, self._y_size, num_total_points, 1)))\n",
    "\n",
    "    # [batch_size, num_total_points, y_size]\n",
    "    # squeeze dim 3 and reorder\n",
    "    y_values = torch.transpose(torch.squeeze(y_values, dim = 3), dim0 = 1, dim1 = 2)\n",
    "\n",
    "    if self._testing:\n",
    "      # Select the targets (all)\n",
    "      target_x = x_values\n",
    "      target_y = y_values\n",
    "\n",
    "      # Select the observations (slicing instead of tf.gather and reordering based on permutation)\n",
    "      idx = torch.randperm(num_target)\n",
    "      context_x = x_values[:, idx[:num_context], :]\n",
    "      context_y = y_values[:, idx[:num_context], :]\n",
    "\n",
    "    else:\n",
    "      # Select the targets which will consist of the context points as well as\n",
    "      # some new target points\n",
    "      target_x = x_values[:, :num_target + num_context, :]\n",
    "      target_y = y_values[:, :num_target + num_context, :]\n",
    "\n",
    "      # Select the observations\n",
    "      context_x = x_values[:, :num_context, :]\n",
    "      context_y = y_values[:, :num_context, :]\n",
    "\n",
    "    query = ((context_x, context_y), target_x)\n",
    "\n",
    "    return NPRegressionDescription(\n",
    "        query = query,\n",
    "        target_y = target_y,\n",
    "        num_total_points = target_x.size(dim = 1),\n",
    "        num_context_points = num_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_data(target_x, target_y, context_x, context_y):\n",
    "    \"\"\" Plotly go function that creates plot from test data\n",
    "\n",
    "    Args:\n",
    "        target_x (_type_): _description_\n",
    "        target_y (_type_): _description_\n",
    "        context_x (_type_): _description_\n",
    "        context_y (_type_): _description_\n",
    "    \"\"\"    \n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add line of target points\n",
    "    fig.add_trace(go.Scatter(x = torch.squeeze(target_x), y = torch.squeeze(target_y), mode = 'lines', name = 'Target'))\n",
    "    \n",
    "    # Add line of context points\n",
    "    fig.add_trace(go.Scatter(x = torch.squeeze(context_x), y = torch.squeeze(context_y), mode = 'markers', name = 'Context'))\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CONTEXT_POINTS = 50 #@param {type:\"number\"}\n",
    "random_kernel_parameters = True #@param {type:\"boolean\"}\n",
    "\n",
    "# Train dataset\n",
    "dataset_train = GPCurvesReader(\n",
    "    batch_size = 16, max_num_context = MAX_CONTEXT_POINTS, random_kernel_parameters = random_kernel_parameters)\n",
    "data_train = dataset_train.generate_curves()\n",
    "\n",
    "# Test dataset\n",
    "dataset_test = GPCurvesReader(\n",
    "    batch_size = 1, max_num_context = MAX_CONTEXT_POINTS, testing = True, random_kernel_parameters = random_kernel_parameters)\n",
    "data_test = dataset_test.generate_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train data context_x: torch.Size([16, 5, 1])\n",
      "Size of train data context_y:  torch.Size([16, 5, 1])\n",
      "Size of train data target_x:  torch.Size([16, 23, 1])\n",
      "Size of train data target_y:  torch.Size([16, 23, 1])\n"
     ]
    }
   ],
   "source": [
    "# Unpack train data (better to visualise)\n",
    "((context_x, context_y), target_x) = data_train.query\n",
    "target_y = data_train.target_y\n",
    "\n",
    "print(f\"Size of train data context_x: {context_x.size()}\")\n",
    "print(\"Size of train data context_y: \", context_y.size())\n",
    "\n",
    "print(\"Size of train data target_x: \", target_x.size())\n",
    "print(\"Size of train data target_y: \", target_y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of context_x:  torch.Size([1, 37, 1])\n",
      "Size of context_y:  torch.Size([1, 37, 1])\n",
      "Size of target_x:  torch.Size([1, 400, 1])\n",
      "Size of target_y:  torch.Size([1, 400, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Target",
         "type": "scatter",
         "x": [
          -2,
          -1.9900000095367432,
          -1.9800000190734863,
          -1.9700000286102295,
          -1.9600000381469727,
          -1.9500000476837158,
          -1.940000057220459,
          -1.9299999475479126,
          -1.9199999570846558,
          -1.909999966621399,
          -1.899999976158142,
          -1.8899999856948853,
          -1.8799999952316284,
          -1.8700000047683716,
          -1.8600000143051147,
          -1.8499999046325684,
          -1.840000033378601,
          -1.8300000429153442,
          -1.8200000524520874,
          -1.8100000619888306,
          -1.8000000715255737,
          -1.790000081062317,
          -1.78000009059906,
          -1.7699999809265137,
          -1.7599999904632568,
          -1.75,
          -1.7400000095367432,
          -1.7300000190734863,
          -1.7200000286102295,
          -1.7100000381469727,
          -1.7000000476837158,
          -1.6899999380111694,
          -1.6799999475479126,
          -1.6699999570846558,
          -1.659999966621399,
          -1.649999976158142,
          -1.6399999856948853,
          -1.6299999952316284,
          -1.6200000047683716,
          -1.6099998950958252,
          -1.600000023841858,
          -1.590000033378601,
          -1.5800000429153442,
          -1.5700000524520874,
          -1.5600000619888306,
          -1.5500000715255737,
          -1.540000081062317,
          -1.5299999713897705,
          -1.5199999809265137,
          -1.5099999904632568,
          -1.5,
          -1.4900000095367432,
          -1.4800000190734863,
          -1.4700000286102295,
          -1.4600000381469727,
          -1.4499999284744263,
          -1.440000057220459,
          -1.4300000667572021,
          -1.4200000762939453,
          -1.4100000858306885,
          -1.4000000953674316,
          -1.3900001049041748,
          -1.380000114440918,
          -1.3700000047683716,
          -1.3600000143051147,
          -1.350000023841858,
          -1.340000033378601,
          -1.3300000429153442,
          -1.3200000524520874,
          -1.3100000619888306,
          -1.3000000715255737,
          -1.2899999618530273,
          -1.2799999713897705,
          -1.2699999809265137,
          -1.2599999904632568,
          -1.25,
          -1.2400000095367432,
          -1.2300000190734863,
          -1.2200000286102295,
          -1.209999918937683,
          -1.2000000476837158,
          -1.190000057220459,
          -1.1800000667572021,
          -1.1700000762939453,
          -1.1600000858306885,
          -1.1500000953674316,
          -1.1400001049041748,
          -1.1299999952316284,
          -1.1200000047683716,
          -1.1100000143051147,
          -1.100000023841858,
          -1.090000033378601,
          -1.0800000429153442,
          -1.0700000524520874,
          -1.0600000619888306,
          -1.0499999523162842,
          -1.0399999618530273,
          -1.0299999713897705,
          -1.0199999809265137,
          -1.0099999904632568,
          -0.9999999403953552,
          -0.9899999499320984,
          -0.9799999594688416,
          -0.9699999690055847,
          -0.9599999785423279,
          -0.949999988079071,
          -0.9399999976158142,
          -0.9300000071525574,
          -0.9199999570846558,
          -0.9099999666213989,
          -0.8999999761581421,
          -0.8899999856948853,
          -0.8799999952316284,
          -0.8700000047683716,
          -0.8600000143051147,
          -0.8500000238418579,
          -0.8399999737739563,
          -0.8299999833106995,
          -0.8199999928474426,
          -0.8100000023841858,
          -0.800000011920929,
          -0.7900000214576721,
          -0.7800000309944153,
          -0.7700000405311584,
          -0.7599999904632568,
          -0.75,
          -0.7400000095367432,
          -0.7300000190734863,
          -0.7200000286102295,
          -0.7100000381469727,
          -0.7000000476837158,
          -0.690000057220459,
          -0.6800000071525574,
          -0.6700000166893005,
          -0.6600000262260437,
          -0.6500000357627869,
          -0.6399999856948853,
          -0.6299999952316284,
          -0.6200000047683716,
          -0.6100000143051147,
          -0.5999999642372131,
          -0.5899999737739563,
          -0.5799999833106995,
          -0.5699999928474426,
          -0.5600000023841858,
          -0.550000011920929,
          -0.5400000214576721,
          -0.5300000309944153,
          -0.5199999809265137,
          -0.5099999904632568,
          -0.5,
          -0.49000000953674316,
          -0.47999998927116394,
          -0.4699999988079071,
          -0.4599999785423279,
          -0.44999998807907104,
          -0.4399999976158142,
          -0.429999977350235,
          -0.41999998688697815,
          -0.4099999964237213,
          -0.4000000059604645,
          -0.39000001549720764,
          -0.3799999952316284,
          -0.3700000047683716,
          -0.36000001430511475,
          -0.3499999940395355,
          -0.3400000035762787,
          -0.33000001311302185,
          -0.3199999928474426,
          -0.3100000023841858,
          -0.29999998211860657,
          -0.28999999165534973,
          -0.2800000011920929,
          -0.26999998092651367,
          -0.25999999046325684,
          -0.25,
          -0.23999999463558197,
          -0.22999998927116394,
          -0.2199999988079071,
          -0.20999999344348907,
          -0.19999998807907104,
          -0.1899999976158142,
          -0.17999999225139618,
          -0.17000000178813934,
          -0.1599999964237213,
          -0.14999999105930328,
          -0.14000000059604645,
          -0.12999999523162842,
          -0.11999999731779099,
          -0.10999999940395355,
          -0.09999999403953552,
          -0.08999999612569809,
          -0.07999999821186066,
          -0.07000000029802322,
          -0.05999999865889549,
          -0.04999999701976776,
          -0.03999999910593033,
          -0.029999997466802597,
          -0.019999997690320015,
          -0.009999997913837433,
          0,
          0.009999999776482582,
          0.019999999552965164,
          0.029999999329447746,
          0.03999999910593033,
          0.05000000074505806,
          0.05999999865889549,
          0.07000000029802322,
          0.07999999821186066,
          0.08999999612569809,
          0.10000000149011612,
          0.10999999940395355,
          0.11999999731779099,
          0.12999999523162842,
          0.14000000059604645,
          0.14999999105930328,
          0.1599999964237213,
          0.17000000178813934,
          0.17999999225139618,
          0.1899999976158142,
          0.20000000298023224,
          0.20999999344348907,
          0.2199999988079071,
          0.22999998927116394,
          0.23999999463558197,
          0.25,
          0.25999999046325684,
          0.26999998092651367,
          0.2800000011920929,
          0.28999999165534973,
          0.29999998211860657,
          0.3100000023841858,
          0.3199999928474426,
          0.32999998331069946,
          0.3400000035762787,
          0.3499999940395355,
          0.35999998450279236,
          0.3700000047683716,
          0.3799999952316284,
          0.38999998569488525,
          0.4000000059604645,
          0.4099999964237213,
          0.42000001668930054,
          0.4300000071525574,
          0.4399999976158142,
          0.45000001788139343,
          0.46000000834465027,
          0.4699999988079071,
          0.47999998927116394,
          0.4899999797344208,
          0.5,
          0.5099999904632568,
          0.5199999809265137,
          0.5299999713897705,
          0.5399999618530273,
          0.550000011920929,
          0.5600000023841858,
          0.5699999928474426,
          0.5799999833106995,
          0.5899999737739563,
          0.6000000238418579,
          0.6100000143051147,
          0.6200000047683716,
          0.6299999952316284,
          0.6399999856948853,
          0.6499999761581421,
          0.6599999666213989,
          0.6699999570846558,
          0.6800000071525574,
          0.6899999976158142,
          0.699999988079071,
          0.7099999785423279,
          0.7200000286102295,
          0.7300000190734863,
          0.7400000095367432,
          0.75,
          0.7600000500679016,
          0.7700000405311584,
          0.7800000309944153,
          0.7900000214576721,
          0.800000011920929,
          0.8100000023841858,
          0.8199999928474426,
          0.8299999833106995,
          0.8400000333786011,
          0.8500000238418579,
          0.8600000143051147,
          0.8700000047683716,
          0.8799999952316284,
          0.8899999856948853,
          0.8999999761581421,
          0.9099999666213989,
          0.9200000166893005,
          0.9300000071525574,
          0.9399999976158142,
          0.949999988079071,
          0.9599999785423279,
          0.9699999690055847,
          0.9799999594688416,
          0.9899999499320984,
          1,
          1.0099999904632568,
          1.0199999809265137,
          1.0299999713897705,
          1.0399999618530273,
          1.0499999523162842,
          1.059999942779541,
          1.0699999332427979,
          1.0799999237060547,
          1.0899999141693115,
          1.0999999046325684,
          1.1100000143051147,
          1.1200000047683716,
          1.1299999952316284,
          1.1399999856948853,
          1.149999976158142,
          1.159999966621399,
          1.1699999570846558,
          1.1799999475479126,
          1.190000057220459,
          1.2000000476837158,
          1.2100000381469727,
          1.2200000286102295,
          1.2300000190734863,
          1.2400000095367432,
          1.25,
          1.2599999904632568,
          1.2700001001358032,
          1.2799999713897705,
          1.2899999618530273,
          1.2999999523162842,
          1.309999942779541,
          1.3199999332427979,
          1.3299999237060547,
          1.3399999141693115,
          1.350000023841858,
          1.3600000143051147,
          1.3700000047683716,
          1.3799999952316284,
          1.3899999856948853,
          1.399999976158142,
          1.409999966621399,
          1.4199999570846558,
          1.4300000667572021,
          1.440000057220459,
          1.4500000476837158,
          1.4600000381469727,
          1.4700000286102295,
          1.4800000190734863,
          1.4900000095367432,
          1.5,
          1.5100001096725464,
          1.5199999809265137,
          1.5299999713897705,
          1.5399999618530273,
          1.5499999523162842,
          1.559999942779541,
          1.5699999332427979,
          1.5799999237060547,
          1.590000033378601,
          1.600000023841858,
          1.6100000143051147,
          1.6200000047683716,
          1.6299999952316284,
          1.6399999856948853,
          1.649999976158142,
          1.659999966621399,
          1.6700000762939453,
          1.6799999475479126,
          1.6899999380111694,
          1.6999999284744263,
          1.709999918937683,
          1.71999990940094,
          1.7299998998641968,
          1.7399998903274536,
          1.75,
          1.7599999904632568,
          1.7699999809265137,
          1.7799999713897705,
          1.7899999618530273,
          1.7999999523162842,
          1.809999942779541,
          1.8199999332427979,
          1.8300000429153442,
          1.840000033378601,
          1.850000023841858,
          1.8600000143051147,
          1.8700000047683716,
          1.8799999952316284,
          1.8899999856948853,
          1.899999976158142,
          1.9100000858306885,
          1.9199999570846558,
          1.9299999475479126,
          1.9399999380111694,
          1.9499999284744263,
          1.959999918937683,
          1.96999990940094,
          1.9799998998641968,
          1.9900000095367432
         ],
         "y": [
          -0.3966307044029236,
          -0.4714704155921936,
          -0.44971030950546265,
          -0.4899865388870239,
          -0.5342515110969543,
          -0.5278094410896301,
          -0.5295414924621582,
          -0.5219295024871826,
          -0.5452232956886292,
          -0.5741095542907715,
          -0.6090467572212219,
          -0.635878324508667,
          -0.6393382549285889,
          -0.6279345750808716,
          -0.6696581244468689,
          -0.6379110813140869,
          -0.6227418780326843,
          -0.6340338587760925,
          -0.6195756793022156,
          -0.6300682425498962,
          -0.623904287815094,
          -0.6289734840393066,
          -0.5948571562767029,
          -0.6092576384544373,
          -0.6035908460617065,
          -0.5709372162818909,
          -0.5662640333175659,
          -0.6022853255271912,
          -0.5606256723403931,
          -0.5178244113922119,
          -0.5033398866653442,
          -0.44899746775627136,
          -0.4794975519180298,
          -0.4598890244960785,
          -0.46755272150039673,
          -0.4077491760253906,
          -0.4043826162815094,
          -0.38851043581962585,
          -0.34561583399772644,
          -0.3459989130496979,
          -0.32845330238342285,
          -0.2848600149154663,
          -0.2705899775028229,
          -0.2209121584892273,
          -0.19003602862358093,
          -0.2127964198589325,
          -0.16788184642791748,
          -0.1419249325990677,
          -0.13677065074443817,
          -0.07837557792663574,
          -0.06109324097633362,
          -0.059665169566869736,
          -0.028558865189552307,
          -0.0049100592732429504,
          0.004041262902319431,
          0.014350265264511108,
          0.04264506697654724,
          0.03559943288564682,
          0.09583771973848343,
          0.07664331793785095,
          0.13034862279891968,
          0.1388556957244873,
          0.18423256278038025,
          0.18652445077896118,
          0.19206355512142181,
          0.18693551421165466,
          0.24913077056407928,
          0.24260349571704865,
          0.2742864787578583,
          0.3137839436531067,
          0.3509501814842224,
          0.3150140941143036,
          0.3555981516838074,
          0.35639265179634094,
          0.3250204026699066,
          0.37742939591407776,
          0.412158727645874,
          0.39656007289886475,
          0.44656801223754883,
          0.4453704357147217,
          0.4349731206893921,
          0.4759543240070343,
          0.46039140224456787,
          0.47512683272361755,
          0.5042352676391602,
          0.5146391987800598,
          0.4894864559173584,
          0.529462456703186,
          0.5507674813270569,
          0.5339457988739014,
          0.547204315662384,
          0.5642808079719543,
          0.578217089176178,
          0.5964581370353699,
          0.5928140878677368,
          0.5880469679832458,
          0.6380454897880554,
          0.5659623742103577,
          0.6130837202072144,
          0.6443147659301758,
          0.6342121958732605,
          0.6830145716667175,
          0.6331398487091064,
          0.6488367915153503,
          0.7077981233596802,
          0.6549475789070129,
          0.6582498550415039,
          0.6941766738891602,
          0.6611678004264832,
          0.6784261465072632,
          0.6611779928207397,
          0.6759368777275085,
          0.7208023071289062,
          0.6549704074859619,
          0.6875417232513428,
          0.6706690788269043,
          0.665410041809082,
          0.7008887529373169,
          0.698592483997345,
          0.7041184306144714,
          0.6793486475944519,
          0.7135272026062012,
          0.6708411574363708,
          0.6613542437553406,
          0.6733334064483643,
          0.6743881106376648,
          0.6953529119491577,
          0.6730356216430664,
          0.6877685785293579,
          0.6490619778633118,
          0.675243079662323,
          0.6502866744995117,
          0.6665685772895813,
          0.6905826926231384,
          0.6506813168525696,
          0.6747031807899475,
          0.6314118504524231,
          0.6394952535629272,
          0.6795511245727539,
          0.6188890933990479,
          0.627898633480072,
          0.6326871514320374,
          0.6622700095176697,
          0.6262931227684021,
          0.6331640481948853,
          0.6102476716041565,
          0.6074355244636536,
          0.6509405970573425,
          0.618049681186676,
          0.6024296283721924,
          0.6352729797363281,
          0.5799298882484436,
          0.5757178664207458,
          0.5662452578544617,
          0.5736485123634338,
          0.5964858531951904,
          0.6113563776016235,
          0.5606029033660889,
          0.5553913116455078,
          0.5649101734161377,
          0.5019441843032837,
          0.4839836061000824,
          0.4887056350708008,
          0.46905970573425293,
          0.42784273624420166,
          0.4427162706851959,
          0.4571470320224762,
          0.41884487867355347,
          0.41253769397735596,
          0.3922860026359558,
          0.35813096165657043,
          0.36954158544540405,
          0.3446017801761627,
          0.3548603355884552,
          0.29846256971359253,
          0.2940928339958191,
          0.2739594876766205,
          0.2884827256202698,
          0.24024638533592224,
          0.231766477227211,
          0.2297666072845459,
          0.1649712175130844,
          0.20983338356018066,
          0.12457297742366791,
          0.11781827360391617,
          0.11368755251169205,
          0.11924545466899872,
          0.09998392313718796,
          0.07885599136352539,
          0.05785796046257019,
          0.04027464613318443,
          0.05238855630159378,
          0.024984043091535568,
          0.06280909478664398,
          0.012977821752429008,
          -0.013119686394929886,
          -0.018102416768670082,
          -0.008370270021259785,
          -0.023758161813020706,
          -0.0383010171353817,
          -0.05926712974905968,
          -0.061368562281131744,
          -0.033132992684841156,
          -0.09097027778625488,
          -0.03718532994389534,
          -0.07521689683198929,
          -0.07212758809328079,
          -0.0850529670715332,
          -0.07553151994943619,
          -0.04834049567580223,
          -0.03453521430492401,
          -0.021879281848669052,
          -0.0629321038722992,
          -0.05539407953619957,
          -0.03535380959510803,
          -0.03474385291337967,
          -0.0028470829129219055,
          -0.0003322875127196312,
          -0.008241771720349789,
          -0.021514134481549263,
          0.00018275994807481766,
          -0.047082431614398956,
          -0.0007237636018544436,
          -0.0008903034031391144,
          0.010538929142057896,
          -0.014069681987166405,
          0.030951716005802155,
          0.0908207818865776,
          0.05632569640874863,
          0.05208256095647812,
          0.02659549191594124,
          0.04295264184474945,
          0.055365972220897675,
          0.061744656413793564,
          -0.0034262314438819885,
          0.03393403813242912,
          0.025303950533270836,
          0.04516054317355156,
          0.07211339473724365,
          0.06629543751478195,
          0.04168954864144325,
          0.044227663427591324,
          0.09043426811695099,
          0.04201725870370865,
          0.015307620167732239,
          0.04352628439664841,
          -0.004120353609323502,
          0.020955514162778854,
          -0.01075197383761406,
          -0.009641334414482117,
          -0.01753697358071804,
          0.01728009060025215,
          -0.036732882261276245,
          -0.020489906892180443,
          -0.051317248493433,
          -0.052052099257707596,
          -0.05143289268016815,
          -0.07146787643432617,
          -0.09419138729572296,
          -0.09439920634031296,
          -0.08851520717144012,
          -0.09450428932905197,
          -0.10340896993875504,
          -0.12595510482788086,
          -0.16890542209148407,
          -0.17401441931724548,
          -0.18855184316635132,
          -0.1725492775440216,
          -0.2102893739938736,
          -0.23696404695510864,
          -0.23997929692268372,
          -0.24509261548519135,
          -0.2635401487350464,
          -0.2748744785785675,
          -0.27528437972068787,
          -0.31090113520622253,
          -0.2775113880634308,
          -0.2941187918186188,
          -0.32852107286453247,
          -0.2883986830711365,
          -0.30617111921310425,
          -0.32721421122550964,
          -0.3383552134037018,
          -0.3326151967048645,
          -0.3559437394142151,
          -0.32798999547958374,
          -0.377536803483963,
          -0.3604053258895874,
          -0.37384936213493347,
          -0.37295472621917725,
          -0.39439940452575684,
          -0.38231635093688965,
          -0.3755326569080353,
          -0.42343252897262573,
          -0.3853183686733246,
          -0.37834757566452026,
          -0.37572064995765686,
          -0.39163222908973694,
          -0.37878119945526123,
          -0.3674508035182953,
          -0.3323293626308441,
          -0.3745621144771576,
          -0.36991602182388306,
          -0.34029102325439453,
          -0.3400236666202545,
          -0.3390076458454132,
          -0.29195326566696167,
          -0.2922663986682892,
          -0.30470314621925354,
          -0.31527918577194214,
          -0.26229408383369446,
          -0.28596261143684387,
          -0.24428480863571167,
          -0.21255624294281006,
          -0.19904378056526184,
          -0.1759459376335144,
          -0.1957516074180603,
          -0.1912243366241455,
          -0.17849275469779968,
          -0.1632581353187561,
          -0.11962004005908966,
          -0.10098692774772644,
          -0.09501950442790985,
          -0.11948473006486893,
          -0.0789564922451973,
          -0.06205190345644951,
          -0.03617625683546066,
          0.0155646912753582,
          -0.028767772018909454,
          0.004010678734630346,
          -0.011394022032618523,
          0.010528385639190674,
          0.03412705659866333,
          0.00847102701663971,
          0.042689718306064606,
          -0.006912883371114731,
          -0.009734068065881729,
          0.04703928902745247,
          0.04421794414520264,
          0.04025469347834587,
          -0.025929078459739685,
          0.03749339282512665,
          -0.01839582808315754,
          0.04173284024000168,
          -0.003959459252655506,
          0.015401582233607769,
          -0.021534722298383713,
          0.0021996386349201202,
          -0.02666693553328514,
          -0.04492538049817085,
          -0.05537869408726692,
          -0.05115950107574463,
          -0.024027638137340546,
          -0.05253574624657631,
          -0.07078415900468826,
          -0.09717347472906113,
          -0.1510506272315979,
          -0.11092006415128708,
          -0.18698650598526,
          -0.15022239089012146,
          -0.18735933303833008,
          -0.1741531491279602,
          -0.223525732755661,
          -0.24909670650959015,
          -0.23201414942741394,
          -0.2752619683742523,
          -0.28099381923675537,
          -0.2813320755958557,
          -0.324775755405426,
          -0.3040928244590759,
          -0.3401850759983063,
          -0.36510294675827026,
          -0.3232883810997009,
          -0.3965350389480591,
          -0.39822426438331604,
          -0.47527235746383667,
          -0.44557997584342957,
          -0.4553799331188202,
          -0.4768710434436798,
          -0.44905245304107666,
          -0.5080937147140503,
          -0.5185285210609436,
          -0.5571184754371643,
          -0.5715060830116272,
          -0.5771879553794861,
          -0.5699992179870605,
          -0.624807596206665,
          -0.6099527478218079,
          -0.6111346483230591,
          -0.6335678696632385,
          -0.6177855134010315,
          -0.6324602961540222,
          -0.647800087928772,
          -0.6385119557380676,
          -0.6501159071922302,
          -0.6904618144035339,
          -0.6788818836212158,
          -0.7004164457321167,
          -0.7388824820518494,
          -0.7445219159126282
         ]
        },
        {
         "mode": "markers",
         "name": "Context",
         "type": "scatter",
         "x": [
          -0.8199999928474426,
          -0.6500000357627869,
          0.07999999821186066,
          0.3199999928474426,
          -0.6399999856948853,
          -1.1299999952316284,
          1.25,
          1.2400000095367432,
          -1.2000000476837158,
          0.05999999865889549,
          1.059999942779541,
          -0.75,
          -0.5,
          -0.8899999856948853,
          0.8899999856948853,
          0.38999998569488525,
          -0.17999999225139618,
          1.0199999809265137,
          -1.8100000619888306,
          1.5299999713897705,
          -0.08999999612569809,
          0.42000001668930054,
          -0.5899999737739563,
          -1.0600000619888306,
          0.7600000500679016,
          -0.6600000262260437,
          -1.8899999856948853,
          0.6299999952316284,
          0.6499999761581421,
          0.10000000149011612,
          -1.380000114440918,
          -1.9299999475479126,
          -0.8100000023841858,
          -1.7000000476837158,
          -1.5700000524520874,
          0.8600000143051147,
          1.3199999332427979
         ],
         "y": [
          0.698592483997345,
          0.6747031807899475,
          -0.07553151994943619,
          0.055365972220897675,
          0.6314118504524231,
          0.529462456703186,
          -0.06205190345644951,
          -0.0789564922451973,
          0.4349731206893921,
          -0.07212758809328079,
          -0.29195326566696167,
          0.6743881106376648,
          0.6352729797363281,
          0.6759368777275085,
          -0.37295472621917725,
          0.06629543751478195,
          0.20983338356018066,
          -0.36991602182388306,
          -0.6300682425498962,
          -0.05253574624657631,
          0.05238855630159378,
          0.09043426811695099,
          0.6326871514320374,
          0.5928140878677368,
          -0.2775113880634308,
          0.6506813168525696,
          -0.635878324508667,
          -0.12595510482788086,
          -0.17401441931724548,
          -0.03453521430492401,
          0.18423256278038025,
          -0.5219295024871826,
          0.7041184306144714,
          -0.5033398866653442,
          -0.2209121584892273,
          -0.377536803483963,
          0.03412705659866333
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Unpack test data (better to visualise)\n",
    "((context_x, context_y), target_x) = data_test.query\n",
    "target_y = data_test.target_y\n",
    "\n",
    "# Contexts are a subset \n",
    "print(\"Size of test data context_x: \", context_x.size())\n",
    "print(\"Size of test data context_y: \", context_y.size())\n",
    "\n",
    "print(\"Size of test data target_x: \", target_x.size())\n",
    "print(\"Size of test data target_y: \", target_y.size())\n",
    "\n",
    "# Plot\n",
    "plot_test_data(target_x, target_y, context_x, context_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "::\n",
    "\n",
    "    input -> [linear -> relu ->] * 4\n",
    "          -> Mean\n",
    "          -> mu, sigma  \n",
    "          -> MSELoss\n",
    "          -> loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch MLP utlity method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility methods\n",
    "def batch_mlp(input, output_sizes, variable_scope):\n",
    "  \"\"\"Apply MLP to the final axis of a 3D tensor (reusing already defined MLPs).\n",
    "  \n",
    "  Args:\n",
    "    input: input tensor of shape [B,n,d_in].\n",
    "    output_sizes: An iterable containing the output sizes of the MLP as defined \n",
    "        in `basic.Linear`. (e.g. [128, 128, 128, 128])\n",
    "    variable_scope: String giving the name of the variable scope. If this is set\n",
    "        to be the same as a previously defined MLP, then the weights are reused.\n",
    "    \n",
    "  Returns:\n",
    "    tensor of shape [B,n,d_out] where d_out=output_sizes[-1]\n",
    "  \"\"\"\n",
    "  # Get the shapes of the input and reshape to parallelise across observations\n",
    "  # d_in considered filter_size\n",
    "  batch_size, _ , filter_size = list(input.shape)\n",
    "  # Combines datapoints across batches (first dim) but preserved filter_size as last dimension (second dim)\n",
    "  output = torch.reshape(input, shape = (-1, filter_size))\n",
    "\n",
    "  # Pass through MLP\n",
    "  with tf.variable_scope(variable_scope, reuse=tf.AUTO_REUSE):\n",
    "  # i: number of (layers - 1), last layer defined directly\n",
    "  # size: hidden_size defined per layer\n",
    "    for i, size in enumerate(output_sizes[:-1]):\n",
    "\n",
    "      torch.nn.ReLU(torch.nn.Linear(in_features = filter_size, out_features = size))\n",
    "      output = tf.nn.relu(\n",
    "          tf.layers.dense(output, size, name=\"layer_{}\".format(i)))\n",
    "\n",
    "    # Last layer without a ReLu\n",
    "    output = tf.layers.dense(\n",
    "        output, output_sizes[-1], name=\"layer_{}\".format(i + 1))\n",
    "\n",
    "  # Bring back into original shape\n",
    "  output = tf.reshape(output, (batch_size, -1, output_sizes[-1]))\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "size 128\n",
      "i 1\n",
      "size 128\n",
      "i 2\n",
      "size 128\n"
     ]
    }
   ],
   "source": [
    "output_sizes = [HIDDEN_SIZE]*4\n",
    "\n",
    "for i, size in enumerate(output_sizes[:-1]):\n",
    "    print(\"i\", i)\n",
    "    print(\"size\", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "  \"\"\"Encoder class\"\"\"\n",
    "\n",
    "  def __init__(self, output_sizes, num_latents):\n",
    "    \"\"\"NP Encoder\n",
    "\n",
    "    Instance variables:\n",
    "      output_sizes: An iterable containing the output sizes of the encoding MLP. (e.g. [128, 128, 128, 128])\n",
    "      num_latents: The latent dimensionality.\n",
    "    \"\"\"\n",
    "    # self._ : global variables \n",
    "    self._output_sizes = output_sizes\n",
    "    self._num_latents = num_latents\n",
    "\n",
    "  def __call__(self, x, y):\n",
    "    \"\"\"Encodes the inputs into one representation.\n",
    "\n",
    "    Args:\n",
    "      x: Tensor of shape [B, observations, d_x]. For this 1D regression\n",
    "          task this corresponds to the x-values.\n",
    "      y: Tensor of shape [B, observations, d_y]. For this 1D regression\n",
    "          task this corresponds to the y-values.\n",
    "\n",
    "    Returns:\n",
    "      A normal distribution over tensors of shape [B, num_latents]\n",
    "    \"\"\"\n",
    "\n",
    "    # Concatenate x and y along the last axis \n",
    "    encoder_input = torch.cat(tensors = (x, y), dim = -1)\n",
    "\n",
    "    # Pass last axis through MLP\n",
    "    hidden = batch_mlp(encoder_input, self._output_sizes, \"latent_encoder\")\n",
    "\n",
    "    ###\n",
    "    # Get the shapes of the input and reshape to parallelise across observations\n",
    "    batch_size, _ , filter_size = list(encoder_input.shape)\n",
    "    \n",
    "    # Combines datapoints across batches (first dim) but preserved filter_size as last dimension (second dim)\n",
    "    parallel_encoder_input = torch.reshape(encoder_input, shape = (-1, filter_size))\n",
    "    \n",
    "    # Initialise EncoderNet\n",
    "    encodernet = EncoderNet(filter_size, self._num_latents, self._num_latents)\n",
    "\n",
    "    mu, log_sigma = encodernet(parallel_encoder_input)\n",
    "\n",
    "\n",
    "    ###\n",
    "      \n",
    "    # Aggregator: take the mean over all points\n",
    "    hidden = tf.reduce_mean(hidden, axis=1)\n",
    "    \n",
    "    # Have further MLP layers that map to the parameters of the Gaussian latent\n",
    "    with tf.variable_scope(\"latent_encoder\", reuse=tf.AUTO_REUSE):\n",
    "      # First apply intermediate relu layer \n",
    "      hidden = tf.nn.relu(\n",
    "          tf.layers.dense(hidden, \n",
    "                          (self._output_sizes[-1] + self._num_latents)/2, \n",
    "                          name=\"penultimate_layer\"))\n",
    "      # Then apply further linear layers to output latent mu and log sigma\n",
    "      mu = tf.layers.dense(hidden, self._num_latents, name=\"mean_layer\")\n",
    "      log_sigma = tf.layers.dense(hidden, self._num_latents, name=\"std_layer\")\n",
    "      \n",
    "    # Compute sigma\n",
    "    sigma = 0.1 + 0.9 * tf.sigmoid(log_sigma)\n",
    "\n",
    "    # torch.distributions.normal.Normal(0, 1)\n",
    "    return tf.contrib.distributions.Normal(loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class EncoderNet(nn.Module):\n",
    "    ### Leaving out the additional intermediate layer\n",
    "\n",
    "    def __init__(self, filter_size, hidden_size, num_latents): # Layers and variables are defined in the __init__ method\n",
    "        super(EncoderNet, self).__init__()\n",
    "        # VARIABLES\n",
    "        self.filter_size = filter_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_latents = num_latents\n",
    "\n",
    "        # LAYERS\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(self.filter_size, self.hidden_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc3 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.fc4 = nn.Linear(self.hidden_size, self.num_latents)\n",
    "\n",
    "        # Average pooling\n",
    "\n",
    "        # Output layers\n",
    "        self.olmu = nn.Linear(self.hidden_size, self.num_latents)\n",
    "        self.ollogsig = nn.Linear(self.hidden_size, self.num_latents)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        # Linear layer to both outputs\n",
    "        mu = self.olmu(x)\n",
    "        log_sigma = self.ollogsig(x)\n",
    "\n",
    "        return mu, log_sigma\n",
    "\n",
    "# encodernet = EncoderNet()\n",
    "# print(encodernet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "torch.Size([128, 2])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "encodernet = EncoderNet(filter_size = 2, hidden_size = 128, num_latents = 128)\n",
    "params = list(encodernet.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size()) \n",
    "print(params[1].size()) \n",
    "print(params[2].size()) \n",
    "print(params[3].size()) \n",
    "print(params[4].size()) \n",
    "print(params[5].size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "  \"\"\"Encoder class\"\"\"\n",
    "\n",
    "  def __init__(self, output_sizes, num_latents):\n",
    "    \"\"\"NP Encoder\n",
    "\n",
    "    Instance variables:\n",
    "      output_sizes: An iterable containing the output sizes of the encoding MLP. (e.g. [128, 128, 128, 128])\n",
    "      num_latents: The latent dimensionality.\n",
    "    \"\"\"\n",
    "    # self._ : global variables \n",
    "    self._output_sizes = output_sizes\n",
    "    self._num_latents = num_latents\n",
    "\n",
    "  def __call__(self, x, y):\n",
    "    \"\"\"Encodes the inputs into one representation.\n",
    "\n",
    "    Args:\n",
    "      x: Tensor of shape [B, observations, d_x]. For this 1D regression\n",
    "          task this corresponds to the x-values.\n",
    "      y: Tensor of shape [B, observations, d_y]. For this 1D regression\n",
    "          task this corresponds to the y-values.\n",
    "\n",
    "    Returns:\n",
    "      A normal distribution over tensors of shape [B, num_latents]\n",
    "    \"\"\"\n",
    "\n",
    "    # Concatenate x and y along the last axis \n",
    "    encoder_input = torch.cat(tensors = (x, y), dim = -1)\n",
    "\n",
    "    \n",
    "\n",
    "    # Pass last axis through MLP\n",
    "    hidden = batch_mlp(encoder_input, self._output_sizes, \"latent_encoder\")\n",
    "      \n",
    "    # Aggregator: take the mean over all points\n",
    "    hidden = tf.reduce_mean(hidden, axis=1)\n",
    "    \n",
    "    # Have further MLP layers that map to the parameters of the Gaussian latent\n",
    "    with tf.variable_scope(\"latent_encoder\", reuse=tf.AUTO_REUSE):\n",
    "      # First apply intermediate relu layer \n",
    "      hidden = tf.nn.relu(\n",
    "          tf.layers.dense(hidden, \n",
    "                          (self._output_sizes[-1] + self._num_latents)/2, \n",
    "                          name=\"penultimate_layer\"))\n",
    "      # Then apply further linear layers to output latent mu and log sigma\n",
    "      mu = tf.layers.dense(hidden, self._num_latents, name=\"mean_layer\")\n",
    "      log_sigma = tf.layers.dense(hidden, self._num_latents, name=\"std_layer\")\n",
    "      \n",
    "    # Compute sigma\n",
    "    sigma = 0.1 + 0.9 * tf.sigmoid(log_sigma)\n",
    "\n",
    "    # torch.distributions.normal.Normal(0, 1)\n",
    "    return tf.contrib.distributions.Normal(loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6695e+00,  1.3893e+00],\n",
       "        [-1.6097e+00,  6.0845e-01],\n",
       "        [ 1.5475e+00,  1.2541e+00],\n",
       "        [ 9.6082e-01, -6.3821e-02],\n",
       "        [ 1.1155e+00,  1.9211e-01],\n",
       "        [ 1.7744e+00, -5.2131e-01],\n",
       "        [ 1.3607e+00, -4.6908e-01],\n",
       "        [-1.2684e+00,  2.2224e-02],\n",
       "        [-7.1997e-02,  2.4700e-01],\n",
       "        [ 6.6764e-01, -1.3847e-01],\n",
       "        [-1.2043e+00, -2.0594e-01],\n",
       "        [ 2.3439e-01, -7.8805e-02],\n",
       "        [ 6.0307e-01,  4.3825e-01],\n",
       "        [-1.3070e+00, -3.2210e-01],\n",
       "        [-1.4676e+00, -4.7742e-01],\n",
       "        [-3.2465e-01,  6.1068e-01],\n",
       "        [ 1.0823e+00,  8.8236e-02],\n",
       "        [-1.8250e+00, -5.8394e-01],\n",
       "        [-9.4264e-01, -3.4113e-01],\n",
       "        [ 2.1516e-01,  7.8454e-01],\n",
       "        [ 1.7815e+00, -1.2643e+00],\n",
       "        [-3.1779e-01, -1.6950e-01],\n",
       "        [-4.3276e-01, -4.1213e-01],\n",
       "        [ 7.4593e-01, -4.5936e-01],\n",
       "        [ 1.3781e+00, -8.7830e-01],\n",
       "        [-1.1310e+00,  3.5035e-01],\n",
       "        [-1.4030e-01, -1.4355e-02],\n",
       "        [ 6.6925e-02, -1.0389e-01],\n",
       "        [-3.1620e-01,  1.1044e-03],\n",
       "        [-8.1968e-01,  1.8380e-01],\n",
       "        [ 1.7398e+00,  1.8113e+00],\n",
       "        [-1.5712e+00, -1.4130e+00],\n",
       "        [ 1.6185e+00,  1.8521e+00],\n",
       "        [ 8.0599e-01,  2.0769e+00],\n",
       "        [-1.8407e-01,  2.8356e-01],\n",
       "        [ 5.7378e-01,  3.9832e-01],\n",
       "        [ 9.6208e-01,  3.6550e-01],\n",
       "        [-2.3767e-01,  3.2747e-01],\n",
       "        [ 7.8556e-01,  4.0275e-01],\n",
       "        [-9.7342e-01,  3.2510e-01],\n",
       "        [-1.7016e+00, -2.1285e-01],\n",
       "        [ 5.3469e-02,  3.7791e-01],\n",
       "        [-1.6778e+00, -2.0344e-01],\n",
       "        [-1.7194e-01,  3.0066e-01],\n",
       "        [-1.5510e+00,  1.2135e-01],\n",
       "        [-1.5031e+00, -1.1970e+00],\n",
       "        [ 2.3441e-01,  7.5115e-02],\n",
       "        [-1.6174e+00, -3.6613e-01],\n",
       "        [ 5.8395e-01, -6.2629e-01],\n",
       "        [-1.6604e+00,  2.4625e-01],\n",
       "        [-6.0018e-01, -1.1686e+00],\n",
       "        [-7.6155e-01, -1.0162e+00],\n",
       "        [ 1.6443e+00, -8.8444e-02],\n",
       "        [-1.8887e+00, -5.6629e-01],\n",
       "        [ 1.9840e+00, -7.4953e-01],\n",
       "        [ 1.8001e+00, -5.1552e-01],\n",
       "        [ 8.0829e-01,  3.7419e-01],\n",
       "        [-5.4796e-01,  1.4538e-01],\n",
       "        [-1.5063e+00,  4.9074e-01],\n",
       "        [-1.8157e+00,  2.0329e-01],\n",
       "        [-1.4920e+00,  1.8677e-01],\n",
       "        [ 1.7845e-01, -6.2453e-01],\n",
       "        [-7.1728e-01,  2.4523e-01],\n",
       "        [ 5.3259e-01, -6.3513e-01],\n",
       "        [ 1.6586e+00,  9.8166e-02],\n",
       "        [-4.0480e-01,  7.3730e-01],\n",
       "        [-1.4750e+00, -4.4065e-01],\n",
       "        [ 3.0420e-01,  3.1478e-01],\n",
       "        [ 4.0705e-01,  1.8995e-01],\n",
       "        [-1.4360e+00, -4.4230e-01],\n",
       "        [-1.9973e+00,  2.9208e-01],\n",
       "        [ 9.1752e-01,  1.7389e-01],\n",
       "        [ 5.9634e-01,  2.5730e-01],\n",
       "        [-1.7592e+00,  4.2180e-01],\n",
       "        [ 9.1523e-01,  1.6715e-01],\n",
       "        [ 7.2524e-01, -1.7190e-01],\n",
       "        [ 1.5224e+00, -4.0314e-01],\n",
       "        [-2.0114e-01, -2.5419e-01],\n",
       "        [ 1.4145e+00, -2.9201e-01],\n",
       "        [-1.3548e+00, -5.8484e-01]])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input = torch.cat(tensors = (context_x, context_y), dim = -1)\n",
    "print(encoder_input.shape)\n",
    "batch_size, _ , filter_size = list(encoder_input.shape)\n",
    "\n",
    "torch.reshape(encoder_input, shape = (-1, filter_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: 0.0, scale: 1.0)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributions.normal.Normal(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
