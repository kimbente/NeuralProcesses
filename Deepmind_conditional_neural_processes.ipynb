{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of Deepmind's official CNPs implementation in Pytorch\n",
    "\n",
    "https://colab.research.google.com/github/deepmind/neural-processes/blob/master/conditional_neural_process.ipynb#scrollTo=SI188jyyJvHl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "- Original Tensorflow (tf) commands are left in as comments.\n",
    "- Creates GP curved with SE kernel\n",
    "- lengthscale and output scale are fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CNP takes as input a `CNPRegressionDescription` namedtuple with fields:\n",
    "#   `query`: a tuple containing ((context_x, context_y), target_x)\n",
    "#   `target_y`: a tesor containing the ground truth for the targets to be\n",
    "#     predicted\n",
    "#   `num_total_points`: A vector containing a scalar that describes the total\n",
    "#     number of datapoints used (context + target)\n",
    "#   `num_context_points`: A vector containing a scalar that describes the number\n",
    "#     of datapoints used as context\n",
    "# The GPCurvesReader returns the newly sampled data in this format at each\n",
    "# iteration\n",
    "\n",
    "CNPRegressionDescription = collections.namedtuple(\n",
    "    \"CNPRegressionDescription\",\n",
    "    (\"query\", \"target_y\", \"num_total_points\", \"num_context_points\"))\n",
    "\n",
    "class GPCurvesReader(object):\n",
    "  \"\"\"Generates curves using a Gaussian Process (GP).\n",
    "\n",
    "  Supports vector inputs (x) and vector outputs (y). Kernel is\n",
    "  mean-squared exponential, using the x-value l2 coordinate distance scaled by\n",
    "  some factor chosen randomly in a range. Outputs are independent gaussian\n",
    "  processes.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               batch_size,\n",
    "               max_num_context,\n",
    "               x_size = 1,\n",
    "               y_size = 1,\n",
    "               l1_scale = 0.4,\n",
    "               sigma_scale = 1.0,\n",
    "               testing = False):\n",
    "    \"\"\"Creates a regression dataset of functions sampled from a GP.\n",
    "\n",
    "    Args:\n",
    "      batch_size: An integer.\n",
    "      max_num_context: The max number of observations in the context.\n",
    "      x_size: Integer >= 1 for length of \"x values\" vector.\n",
    "      y_size: Integer >= 1 for length of \"y values\" vector.\n",
    "      l1_scale: Float; typical scale for kernel distance function.\n",
    "      sigma_scale: Float; typical scale for variance.\n",
    "      testing: Boolean that indicates whether we are testing. If so there are\n",
    "          more targets for visualization.\n",
    "    \"\"\"\n",
    "    self._batch_size = batch_size\n",
    "    self._max_num_context = max_num_context\n",
    "    self._x_size = x_size\n",
    "    self._y_size = y_size\n",
    "    self._l1_scale = l1_scale\n",
    "    self._sigma_scale = sigma_scale\n",
    "    self._testing = testing\n",
    "\n",
    "  def _gaussian_kernel(self, xdata, l1, sigma_f, sigma_noise = 2e-2):\n",
    "    \"\"\"Applies the Gaussian kernel to generate curve data.\n",
    "\n",
    "    Args:\n",
    "      xdata: Tensor with shape `[batch_size, num_total_points, x_size]` with\n",
    "          the values of the x-axis data.\n",
    "      l1: Tensor with shape `[batch_size, y_size, x_size]`, the scale\n",
    "          parameter of the Gaussian kernel.\n",
    "      sigma_f: Float tensor with shape `[batch_size, y_size]`; the magnitude\n",
    "          of the std.\n",
    "      sigma_noise: Float, std of the noise that we add for stability.\n",
    "\n",
    "    Returns:\n",
    "      The kernel, a float tensor with shape\n",
    "      `[batch_size, y_size, num_total_points, num_total_points]`.\n",
    "    \"\"\"\n",
    "    # Extract number of data points from tensor so this works for both testing and training\n",
    "    num_total_points = xdata.shape[1]\n",
    "\n",
    "    # Expand and take the difference\n",
    "    xdata1 = xdata.unsqueeze(dim = 1) # [B, 1, num_total_points, x_size]\n",
    "    xdata2 = xdata.unsqueeze(dim = 2) # [B, num_total_points, 1, x_size]\n",
    "\n",
    "    # xdata1 = tf.expand_dims(xdata, axis=1)  # [B, 1, num_total_points, x_size]\n",
    "    # xdata2 = tf.expand_dims(xdata, axis=2)  # [B, num_total_points, 1, x_size]\n",
    "    diff = xdata1 - xdata2  # [B, num_total_points, num_total_points, x_size]\n",
    "\n",
    "    # Insert dimension for y_size: [B, y_size, num_total_points, num_total_points, x_size]\n",
    "    # same as diff[:, None, :, :, :]\n",
    "    diff_expanded = diff.unsqueeze(dim = 1)\n",
    "\n",
    "    # Scale the differences (lengthscale) and square\n",
    "    # l1[:, :, None, None, :] created explicit dimensions to that dimensionality matches\n",
    "    norm = torch.square(diff_expanded / l1[:, :, None, None, :])\n",
    "    # Norm has shape [B, y_size, num_total_points, num_total_points, x_size]\n",
    "\n",
    "    # norm = tf.square(diff[:, None, :, :, :] / l1[:, :, None, None, :])\n",
    "\n",
    "    # Sum along last dimension (x_size) to reduce this dimension\n",
    "    norm = torch.sum(norm, dim = -1)\n",
    "    # Norm now has shape [B, y_size, num_total_points, num_total_points]\n",
    "\n",
    "    # norm = tf.reduce_sum(norm, -1)  # [B, data_size, num_total_points, num_total_points]\n",
    "\n",
    "    kernel = torch.square(sigma_f)[:, :, None, None] * torch.exp(-0.5 * norm)\n",
    "    # kernel = tf.square(sigma_f)[:, :, None, None] * tf.exp(-0.5 * norm)\n",
    "    # Kernel has shape [B, y_size, num_total_points, num_total_points]\n",
    "\n",
    "    # Add some noise to the diagonal to make the cholesky work.\n",
    "    # sigma_noise.pow(2) = sigma_noise ** 2\n",
    "    kernel = kernel + ((sigma_noise ** 2) * torch.eye(n = num_total_points))\n",
    "    # kernel += (sigma_noise**2) * tf.eye(num_total_points)\n",
    "\n",
    "    return kernel\n",
    "\n",
    "  def generate_curves(self):\n",
    "    \"\"\"Builds the op delivering the data.\n",
    "\n",
    "    Generated functions are `float32` with x values between -2 and 2.\n",
    "    \n",
    "    Returns:\n",
    "      A `CNPRegressionDescription` namedtuple.\n",
    "    \"\"\"\n",
    "    # Sample number of context points between 3 and max_num_content\n",
    "    # Torch: low (inclusive) and high (exclusive)\n",
    "    num_context = torch.randint(low = 3, high = self._max_num_context, size = (1,))\n",
    "    # num_context = tf.random_uniform(shape = [], minval = 3, maxval = self._max_num_context, dtype = tf.int32)\n",
    "\n",
    "    ### X-VALUES ###\n",
    "    # If we are TESTING we want to have more targets and have them evenly distributed in order to plot the function.\n",
    "    if self._testing:\n",
    "      num_target = 400\n",
    "      num_total_points = num_target\n",
    "      # tf.expand_dims or torch.unsqueeze add dimension of length one\n",
    "      # torch.tile create x batch replicas\n",
    "      x_values = torch.tile(input = torch.arange(start = -2., end = 2., step = 1./100).unsqueeze(dim = 0),\n",
    "                 dims = (self._batch_size, 1))\n",
    "     \n",
    "      # Add explicit last dimension\n",
    "      x_values = x_values.unsqueeze(dim = -1)\n",
    "      # x_value has shape (batch_size, num_target, x_size)\n",
    "\n",
    "      # x_values = tf.tile(tf.expand_dims(tf.range(-2., 2. , 1. / 100, dtype = tf.float32), axis = 0),[self._batch_size, 1])\n",
    "      # x_values = tf.expand_dims(x_values, axis=-1)\n",
    "\n",
    "    # During TRAINING the number of target points and their x-positions are selected at random\n",
    "    # Since x_value samples have no order, the kernel looks funky\n",
    "    else:\n",
    "      num_target = torch.randint(low = 2, high = self._max_num_context, size = (1,))\n",
    "      # num_target = tf.random_uniform(shape = (), minval = 2, maxval = self._max_num_context, dtype = tf.int32)\n",
    "      num_total_points = num_context + num_target\n",
    "      # sample unformly between [0, 1), then scale and shift\n",
    "      x_values = ((torch.rand(size = (self._batch_size, num_total_points, self._x_size)) * 4) - 2)\n",
    "      # x_values = tf.random_uniform([self._batch_size, num_total_points, self._x_size], -2, 2)\n",
    "\n",
    "    ### Y-VALUES ###\n",
    "    # Set kernel parameters\n",
    "    # Copy l1_scale and sigma_f into the right shaped tensors\n",
    "    l1 = torch.ones(size = (self._batch_size, self._y_size, self._x_size)) * self._l1_scale\n",
    "    sigma_f = torch.ones(size = (self._batch_size, self._y_size)) * self._sigma_scale\n",
    "\n",
    "    # l1 = (tf.ones(shape = [self._batch_size, self._y_size, self._x_size]) * self._l1_scale)\n",
    "    # sigma_f = tf.ones(shape = [self._batch_size, self._y_size]) * self._sigma_scale\n",
    "\n",
    "    ### GAUSSIAN KERNEL ###\n",
    "    # Pass the x_values through the Gaussian kernel\n",
    "    # [batch_size, y_size, num_total_points, num_total_points]\n",
    "    kernel = self._gaussian_kernel(x_values, l1, sigma_f)\n",
    "\n",
    "    # Computes the Cholesky decomposition for batches of symmetric positive-definite matrices\n",
    "    cholesky = torch.linalg.cholesky(kernel)\n",
    "    # cholesky has shape [batch_size, y_size, num_total_points, num_total_points]\n",
    "\n",
    "    # Calculate Cholesky, using double precision for better stability:\n",
    "    # cholesky = tf.cast(tf.cholesky(tf.cast(kernel, tf.float64)), tf.float32)\n",
    "\n",
    "    # Sample a curve: randn stand for random normal\n",
    "    y_values = torch.matmul(cholesky, torch.randn(size = (self._batch_size, self._y_size, num_total_points, 1)))\n",
    "    # y_values has shape [batch_size, y_size, num_total_points, 1]\n",
    "\n",
    "    # y_values = tf.matmul(cholesky, tf.random_normal([self._batch_size, self._y_size, num_total_points, 1]))\n",
    "\n",
    "    # Squeeze last dimension and transpose last two dimensions\n",
    "    y_values = torch.transpose(input = y_values.squeeze(dim = -1), dim0 = 2, dim1 = 1)\n",
    "    # y_values now has shape [batch_size, num_total_points, y_size]\n",
    "    \n",
    "    # y_values = tf.transpose(tf.squeeze(y_values, 3), [0, 2, 1])\n",
    "\n",
    "    if self._testing:\n",
    "      # Select the targets\n",
    "      target_x = x_values\n",
    "      target_y = y_values\n",
    "\n",
    "      # Select the observations (num_context subset of target)\n",
    "      # Returns a random permutation of integers from 0 to n - 1.\n",
    "      idx = torch.randperm(n = int(num_target))\n",
    "      # idx = tf.random_shuffle(tf.range(num_target))\n",
    "\n",
    "      # Subset first \"num_context\" points from dim 1 into the context\n",
    "      context_x = x_values[:, idx[:num_context], :]\n",
    "      context_y = y_values[:, idx[:num_context], :]\n",
    "\n",
    "      # context_x = tf.gather(x_values, idx[:num_context], axis=1)\n",
    "      # context_y = tf.gather(y_values, idx[:num_context], axis=1)\n",
    "\n",
    "    else:\n",
    "      # Select the targets which will consist of the context points as well as some new target points\n",
    "      # same as target_x = x_values (all values)\n",
    "      target_x = x_values[:, :num_target + num_context, :]\n",
    "      target_y = y_values[:, :num_target + num_context, :]\n",
    "\n",
    "      # Select the observations\n",
    "      context_x = x_values[:, :num_context, :]\n",
    "      context_y = y_values[:, :num_context, :]\n",
    "\n",
    "    query = ((context_x, context_y), target_x)\n",
    "\n",
    "    return CNPRegressionDescription(\n",
    "        query = query,\n",
    "        target_y = target_y,\n",
    "        num_total_points = target_x.shape[1],\n",
    "        # num_total_points=tf.shape(target_x)[1],\n",
    "        num_context_points = num_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resulting sizes of samples:\n",
    "- num_contexts: integer samples uniformly at random from [3, 10) (3 included, 10 excluded)\n",
    "- num_targets: \n",
    "  - TESTING: 400\n",
    "  - TRAINING: sampled between [2, 10) (10: max_num_content, same limit)\n",
    "- num_total\n",
    "  - TESTING: 400 \n",
    "  - TRAINING: [5, 18]\n",
    "\n",
    "### DataGenerator code hierarchy:\n",
    "class GPCurvesReader(object):  \n",
    "- def _gaussian_kernel():  \n",
    "- def generate_curves(self):  \n",
    "    - calls _gaussian_kernel()  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "The encoder **e** is shared between all the context points and consists of an\n",
    "MLP with a handful of layers. For this experiment four layers are enough, but we\n",
    "can still change the number and size of the layers when we build the graph later\n",
    "on via the variable **`encoder_output_sizes`**. Each of the context pairs **(x,\n",
    "y)<sub>i</sub>** results in an individual representation **r<sub>i</sub>** after\n",
    "encoding. These representations are then combined across context points to form\n",
    "a single representation **r** using the aggregator **a**.\n",
    "\n",
    "In this implementation we have included the aggregator **a** in the encoder as\n",
    "we are only taking the mean across all points. The representation **r** produced\n",
    "by the aggregator contains the information about the underlying unknown function\n",
    "**f** that is provided by all the context points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class DeterministicEncoder(nn.Module):\n",
    "# class DeterministicEncoder(object):\n",
    "  \"\"\"The Encoder.\"\"\"\n",
    "\n",
    "  def __init__(self, output_sizes):\n",
    "    \"\"\"CNP encoder.\n",
    "\n",
    "    Args:\n",
    "      output_sizes: An iterable containing the output sizes of the encoding MLP.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self._output_sizes = output_sizes\n",
    "\n",
    "    # PyTorch: need to initiate layers in __init__ not forward()\n",
    "    # First layer - HARDCODE 2\n",
    "    self.module_list = nn.ModuleList([nn.Linear(in_features = 2, out_features = self._output_sizes[0])])\n",
    "    self.module_list.append(nn.ReLU(inplace = True))\n",
    "\n",
    "    for i, size in enumerate(self._output_sizes[1 : -1]):\n",
    "      # i: previous \n",
    "      self.module_list.append(nn.Linear(in_features = self._output_sizes[i], out_features = self._output_sizes[i + 1]))\n",
    "      self.module_list.append(nn.ReLU(inplace = True))\n",
    "\n",
    "    # Last layer without activation\n",
    "    self.module_list.append(nn.Linear(in_features = self._output_sizes[-2], out_features = self._output_sizes[-1]))\n",
    "\n",
    "  def forward(self, context_x, context_y, num_context_points):\n",
    "    \"\"\"Encodes the inputs into one representation.\n",
    "\n",
    "    Args:\n",
    "      context_x: Tensor of size bs x observations x m_ch. For this 1D regression\n",
    "          task this corresponds to the x-values.\n",
    "      context_y: Tensor of size bs x observations x d_ch. For this 1D regression\n",
    "          task this corresponds to the y-values.\n",
    "      num_context_points: A tensor containing a single scalar that indicates the\n",
    "          number of context_points provided in this iteration.\n",
    "\n",
    "    Returns:\n",
    "      representation: The encoded representation averaged over all context \n",
    "          points.\n",
    "    \"\"\"\n",
    "    # Concatenate x and y along the filter axes\n",
    "    # DIFFERS from other implementation which concats along dim = 1\n",
    "    encoder_input = torch.cat((context_x, context_y), dim = -1)\n",
    "    # encoder_input = tf.concat([context_x, context_y], axis = -1)\n",
    "\n",
    "    # Get the shapes of the input and reshape to parallelise across observations\n",
    "    batch_size, _ , filter_size = encoder_input.shape\n",
    "    # batch_size, _ , filter_size = encoder_input.shape.as_list()\n",
    "\n",
    "    # Combine dim batches to improve parallelisation\n",
    "    hidden = torch.reshape(input = encoder_input, shape = (batch_size * num_context_points, -1))\n",
    "    # hidden = tf.reshape(encoder_input, (batch_size * num_context_points, -1))\n",
    "    # Redundant:\n",
    "    # hidden.set_shape((None, filter_size))\n",
    "\n",
    "    # FORWARD\n",
    "    for module in self.module_list:\n",
    "            hidden = module(hidden)\n",
    "\n",
    "    # # Pass through MLP\n",
    "    # with tf.variable_scope(\"encoder\", reuse=tf.AUTO_REUSE):\n",
    "    #  for i, size in enumerate(self._output_sizes[:-1]):\n",
    "    #    hidden = tf.nn.relu(\n",
    "    #       tf.layers.dense(hidden, size, name=\"Encoder_layer_{}\".format(i)))\n",
    "\n",
    "    #  # Last layer without a ReLu\n",
    "    #  hidden = tf.layers.dense(\n",
    "    #      hidden, self._output_sizes[-1], name = \"Encoder_layer_{}\".format(i + 1))\n",
    "\n",
    "    # Bring back into original shape\n",
    "    hidden = torch.reshape(input = hidden, shape = (batch_size, num_context_points, self._output_sizes[-1]))\n",
    "    # hidden = tf.reshape(hidden, (batch_size, num_context_points, size))\n",
    "\n",
    "    # Aggregator: take the mean over all points (dim 1)\n",
    "    representation = torch.mean(input = hidden, dim = 1)\n",
    "    # representation = tf.reduce_mean(hidden, axis=1)\n",
    "\n",
    "    return representation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "Once we have obtained our representation **r** we concatenate it with each of\n",
    "the targets **x<sub>t</sub>** and pass it through the decoder **d**. As with the\n",
    "encoder **e**, the decoder **d** is shared between all the target points and\n",
    "consists of a small MLP with layer sizes defined in **`decoder_output_sizes`**.\n",
    "The decoder outputs a mean **&mu;<sub>t</sub>** and a variance\n",
    "**&sigma;<sub>t</sub>** for each of the targets **x<sub>t</sub>**. To train our\n",
    "CNP we use the log likelihood of the ground truth value **y<sub>t</sub>** under\n",
    "a Gaussian parametrized by these predicted **&mu;<sub>t</sub>** and\n",
    "**&sigma;<sub>t</sub>**.\n",
    "\n",
    "In this implementation we clip the variance **&sigma;<sub>t</sub>** at 0.1 to\n",
    "avoid collapsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F # SoftPlus\n",
    "from torch.distributions import Normal\n",
    "\n",
    "class DeterministicDecoder(nn.Module):\n",
    "  \"\"\"The Decoder.\"\"\"\n",
    "\n",
    "  def __init__(self, output_sizes):\n",
    "    \"\"\"CNP decoder.\n",
    "\n",
    "    Args:\n",
    "      output_sizes: An iterable containing the output sizes of the decoder MLP \n",
    "          as defined in `basic.Linear`.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self._output_sizes = output_sizes\n",
    "\n",
    "    # PyTorch: need to initiate layers in __init__ not forward()\n",
    "    # First layer - HARDCODE 128 + 1\n",
    "    self.module_list = nn.ModuleList([nn.Linear(in_features = self._output_sizes[0] + 1, out_features = self._output_sizes[0])])\n",
    "    self.module_list.append(nn.ReLU(inplace = True))\n",
    "\n",
    "    for i, size in enumerate(self._output_sizes[1 : -1]):\n",
    "      # i: previous \n",
    "      self.module_list.append(nn.Linear(in_features = self._output_sizes[i], out_features = self._output_sizes[i + 1]))\n",
    "      self.module_list.append(nn.ReLU(inplace = True))\n",
    "\n",
    "    # Last layer without activation (Output size is 2)\n",
    "    self.module_list.append(nn.Linear(in_features = self._output_sizes[-2], out_features = self._output_sizes[-1]))\n",
    "\n",
    "  def forward(self, representation, target_x, num_total_points):\n",
    "  # def __call__(self, representation, target_x, num_total_points):\n",
    "    \"\"\"Decodes the individual targets.\n",
    "\n",
    "    Args:\n",
    "      representation: The encoded representation of the context\n",
    "      target_x: The x locations for the target query\n",
    "      num_total_points: The number of target points.\n",
    "\n",
    "    Returns:\n",
    "      dist: A multivariate Gaussian over the target points.\n",
    "      mu: The mean of the multivariate Gaussian.\n",
    "      sigma: The standard deviation of the multivariate Gaussian.\n",
    "    \"\"\"\n",
    "\n",
    "    # Concatenate the representation and the target_x\n",
    "\n",
    "    representation = torch.tile(input = representation.unsqueeze(dim = 1), dims = (1, num_total_points, 1))\n",
    "    # representation = tf.tile(tf.expand_dims(representation, axis=1), [1, num_total_points, 1])\n",
    "\n",
    "    input = torch.concat((representation, target_x), dim = -1)\n",
    "    # input = tf.concat([representation, target_x], axis=-1)\n",
    "\n",
    "    # Get the shapes of the input and reshape to parallelise across observations\n",
    "    batch_size, _ , filter_size = input.shape\n",
    "    # batch_size, _, filter_size = input.shape.as_list()\n",
    "\n",
    "    hidden = torch.reshape(input = input, shape = (batch_size * num_total_points, -1))\n",
    "    # hidden = tf.reshape(input, (batch_size * num_total_points, -1))\n",
    "    # hidden.set_shape((None, filter_size))\n",
    "\n",
    "    # FORWARD\n",
    "    for module in self.module_list: \n",
    "      hidden = module(hidden)\n",
    "\n",
    "    # Pass through MLP\n",
    "    # with tf.variable_scope(\"decoder\", reuse=tf.AUTO_REUSE):\n",
    "    #  for i, size in enumerate(self._output_sizes[:-1]):\n",
    "    #    hidden = tf.nn.relu(\n",
    "    #        tf.layers.dense(hidden, size, name=\"Decoder_layer_{}\".format(i)))\n",
    "\n",
    "    #  # Last layer without a ReLu\n",
    "    #  hidden = tf.layers.dense(\n",
    "    #      hidden, self._output_sizes[-1], name=\"Decoder_layer_{}\".format(i + 1))\n",
    "\n",
    "    # Bring back into original shape\n",
    "    hidden = torch.reshape(input = hidden, shape = (batch_size, num_total_points, -1))\n",
    "    # hidden = tf.reshape(hidden, (batch_size, num_total_points, -1))\n",
    "\n",
    "    # Get the mean an the variance\n",
    "    mu, log_sigma = torch.split(tensor = hidden, split_size_or_sections = (1, 1), dim = -1)\n",
    "    # mu, log_sigma = tf.split(hidden, 2, axis=-1)\n",
    "\n",
    "    # Bound the variance\n",
    "    sigma = 0.1 + 0.9 * F.softplus(log_sigma)\n",
    "    # sigma = 0.1 + 0.9 * tf.nn.softplus(log_sigma)\n",
    "\n",
    "    # Get the distribution\n",
    "    dist = Normal(mu, sigma)\n",
    "    # dist = tf.contrib.distributions.MultivariateNormalDiag(loc = mu, scale_diag = sigma)\n",
    "\n",
    "    return dist, mu, sigma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Now that the main building blocks (encoder, (aggregator) and decoder) of the CNP\n",
    "are defined we can put everything together into one model. Fundamentally this\n",
    "model only needs to include two main methods: 1. A method that returns the log\n",
    "likelihood of the targets' ground truth values under the predicted\n",
    "distribution.This method will be called during training as our loss function. 2.\n",
    "Another method that returns the predicted mean and variance at the target\n",
    "locations in order to evaluate or query the CNP at test time. This second method\n",
    "needs to be defined separately as, unlike the method above, it should not depend\n",
    "on the ground truth target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterministicModel(nn.Module):\n",
    "  \"\"\"The CNP model.\"\"\"\n",
    "\n",
    "  def __init__(self, encoder_output_sizes, decoder_output_sizes):\n",
    "    \"\"\"Initialises the model.\n",
    "\n",
    "    Args:\n",
    "      encoder_output_sizes: An iterable containing the sizes of hidden layers of\n",
    "          the encoder. The last one is the size of the representation r.\n",
    "      decoder_output_sizes: An iterable containing the sizes of hidden layers of\n",
    "          the decoder. The last element should correspond to the dimension of\n",
    "          the y * 2 (it encodes both mean and variance concatenated)\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self._encoder = DeterministicEncoder(encoder_output_sizes)\n",
    "    self._decoder = DeterministicDecoder(decoder_output_sizes)\n",
    "  \n",
    "  def forward(self, query, num_total_points, num_contexts, target_y = None):\n",
    "  # def __call__(self, query, num_total_points, num_contexts, target_y = None):\n",
    "    \"\"\"Returns the predicted mean and variance at the target points.\n",
    "\n",
    "    Args:\n",
    "      query: Array containing ((context_x, context_y), target_x) where:\n",
    "          context_x: Array of shape batch_size x num_context x 1 contains the \n",
    "              x values of the context points.\n",
    "          context_y: Array of shape batch_size x num_context x 1 contains the \n",
    "              y values of the context points.\n",
    "          target_x: Array of shape batch_size x num_target x 1 contains the\n",
    "              x values of the target points.\n",
    "      target_y: The ground truth y values of the target y. An array of \n",
    "          shape batchsize x num_targets x 1.\n",
    "      num_total_points: Number of target points.\n",
    "\n",
    "    Returns:\n",
    "      log_p: The log_probability of the target_y given the predicted\n",
    "      distribution.\n",
    "      mu: The mean of the predicted distribution.\n",
    "      sigma: The variance of the predicted distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    (context_x, context_y), target_x = query\n",
    "\n",
    "    # Pass query through the encoder and the decoder\n",
    "    # Only context passed through encoder\n",
    "    representation = self._encoder(context_x, context_y, num_contexts)\n",
    "    dist, mu, sigma = self._decoder(representation, target_x, num_total_points)\n",
    "\n",
    "    # If we want to calculate the log_prob for training we will make use of the target_y. \n",
    "    # At test time the target_y is not available so we return None\n",
    "    if target_y is not None:\n",
    "      log_p = dist.log_prob(target_y)\n",
    "    else:\n",
    "      log_p = None\n",
    "\n",
    "    return log_p, mu, sigma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Conditional Neural Processes\n",
    "\n",
    "Now that we have defined the dataset as well as our model and its components we\n",
    "can start building everything into the graph. Before we get started we need to\n",
    "set some variables:\n",
    "\n",
    "*   **`TRAINING_ITERATIONS`** - a scalar that describes the number of iterations\n",
    "    for training. At each iteration we will sample a new batch of functions from\n",
    "    the GP, pick some of the points on the curves as our context points **(x,\n",
    "    y)<sub>C</sub>** and some points as our target points **(x,\n",
    "    y)<sub>T</sub>**. We will predict the mean and variance at the target points\n",
    "    given the context and use the log likelihood of the ground truth targets as\n",
    "    our loss to update the model.\n",
    "*   **`MAX_CONTEXT_POINTS`** - a scalar that sets the maximum number of contest\n",
    "    points used during training. The number of context points will then be a\n",
    "    value between 3 and `MAX_CONTEXT_POINTS` that is sampled at random for every\n",
    "    iteration.\n",
    "*   **`PLOT_AFTER`** - a scalar that regulates how often we plot the\n",
    "    intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iterations: 200000\n",
      "Maximum context points: 10\n",
      "Plot after: 20000\n"
     ]
    }
   ],
   "source": [
    "TRAINING_ITERATIONS = int(2e5)\n",
    "MAX_CONTEXT_POINTS = 10\n",
    "PLOT_AFTER = int(2e4)\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "print(f\"Training iterations: {TRAINING_ITERATIONS}\")\n",
    "print(f\"Maximum context points: {MAX_CONTEXT_POINTS}\")\n",
    "print(f\"Plot after: {PLOT_AFTER}\") # results in 10 plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "dataset_train = GPCurvesReader(batch_size = 64, max_num_context = MAX_CONTEXT_POINTS, testing = False)\n",
    "data_train = dataset_train.generate_curves()\n",
    "\n",
    "# Test dataset\n",
    "dataset_test = GPCurvesReader(batch_size = 1, max_num_context = MAX_CONTEXT_POINTS, testing = True)\n",
    "data_test = dataset_test.generate_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract testing data (for visualisation)\n",
    "((context_x, context_y), target_x), target_y, num_total_points, num_context_points = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5, 2])\n",
      "torch.Size([64, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "((context_x, context_y), target_x), target_y, num_total_points, num_context_points = data_train\n",
    "print(torch.cat((context_x, context_y), dim = -1).shape)\n",
    "print(torch.cat((context_x, context_y), dim = 1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_target_data(target_x, target_y, context_x, context_y):\n",
    "  \"\"\"Plots the one instantiation from the test dataset (batchsize 1) including target and context\n",
    "  \n",
    "  Args: \n",
    "    target_x: An array of shape batchsize x number_targets x 1 that contains the\n",
    "        x values of the target points.\n",
    "    target_y: An array of shape batchsize x number_targets x 1 that contains the\n",
    "        y values of the target points.\n",
    "    context_x: An array of shape batchsize x number_context x 1 that contains \n",
    "        the x values of the context points.\n",
    "    context_y: An array of shape batchsize x number_context x 1 that contains \n",
    "        the y values of the context points.\n",
    "  \"\"\"\n",
    "  # Plot everything\n",
    "  plt.plot(target_x[0], target_y[0], 'k:', linewidth = 2)\n",
    "  plt.plot(context_x[0], context_y[0], 'ko', markersize = 10)\n",
    "\n",
    "  # Make the plot pretty\n",
    "  plt.yticks([-2, 0, 2], fontsize = 16)\n",
    "  plt.xticks([-2, 0, 2], fontsize = 16)\n",
    "  plt.ylim([-2, 2])\n",
    "  plt.grid('off')\n",
    "  ax = plt.gca()\n",
    "  ax.set_facecolor('white')\n",
    "  # old: ax.set_axis_bgcolor('white')\n",
    "  plt.title(\"Test data\")\n",
    "  plt.show()\n",
    "\n",
    "plot_target_data(target_x, target_y, context_x, context_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_functions(target_x, target_y, context_x, context_y, pred_y, var):\n",
    "  \"\"\"Plots the predicted mean and variance and the context points.\n",
    "  \n",
    "  Args: \n",
    "    target_x: An array of shape batchsize x number_targets x 1 that contains the\n",
    "        x values of the target points.\n",
    "    target_y: An array of shape batchsize x number_targets x 1 that contains the\n",
    "        y values of the target points.\n",
    "    context_x: An array of shape batchsize x number_context x 1 that contains \n",
    "        the x values of the context points.\n",
    "    context_y: An array of shape batchsize x number_context x 1 that contains \n",
    "        the y values of the context points.\n",
    "    pred_y: An array of shape batchsize x number_targets x 1  that contains the\n",
    "        predicted means of the y values at the target points in target_x.\n",
    "    pred_y: An array of shape batchsize x number_targets x 1  that contains the\n",
    "        predicted variance of the y values at the target points in target_x.\n",
    "  \"\"\"\n",
    "  # Plot everything\n",
    "  plt.plot(target_x[0], pred_y[0], 'b', linewidth=2)\n",
    "  plt.plot(target_x[0], target_y[0], 'k:', linewidth=2)\n",
    "  plt.plot(context_x[0], context_y[0], 'ko', markersize=10)\n",
    "  plt.fill_between(\n",
    "      target_x[0, :, 0],\n",
    "      pred_y[0, :, 0] - var[0, :, 0],\n",
    "      pred_y[0, :, 0] + var[0, :, 0],\n",
    "      alpha=0.2,\n",
    "      facecolor='#65c9f7',\n",
    "      interpolate=True)\n",
    "\n",
    "  # Make the plot pretty\n",
    "  plt.yticks([-2, 0, 2], fontsize=16)\n",
    "  plt.xticks([-2, 0, 2], fontsize=16)\n",
    "  plt.ylim([-2, 2])\n",
    "  plt.grid('off')\n",
    "  ax = plt.gca()\n",
    "  ax.set_facecolor('white')\n",
    "  # old: ax.set_axis_bgcolor('white')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sizes of the layers of the MLPs for the encoder and decoder\n",
    "# The final output layer of the decoder outputs two values, one for the mean and\n",
    "# one for the variance of the prediction at the target location\n",
    "encoder_output_sizes = [128, 128, 128, 128]\n",
    "decoder_output_sizes = [128, 128, 2]\n",
    "\n",
    "# Define the model\n",
    "model = DeterministicModel(encoder_output_sizes, decoder_output_sizes)\n",
    "\n",
    "# Define the loss\n",
    "log_prob, _, _ = model(data_train.query, data_train.num_total_points,\n",
    "                       data_train.num_context_points, data_train.target_y)\n",
    "\n",
    "# log_prob is shape [batch_size, num, 1]\n",
    "# NLL across full batch\n",
    "loss = - log_prob.mean()\n",
    "# loss = - log_prob.mean(dim = 0).sum()\n",
    "# If None (the default), reduces all dimensions\n",
    "# loss = -tf.reduce_mean(log_prob)\n",
    "\n",
    "# Get the predicted mean and variance at the target points for the testing set\n",
    "_, mu, sigma = model(data_test.query, data_test.num_total_points,\n",
    "                     data_test.num_context_points)\n",
    "\n",
    "# Set up the optimizer and train step\n",
    "# optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "# train_step = optimizer.minimize(loss)\n",
    "# init = tf.initialize_all_variables()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4) # 0.0001\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100, loss: -0.7000488042831421\n",
      "Iteration: 200, loss: -0.7027081847190857\n",
      "Iteration: 300, loss: -0.7322787642478943\n",
      "Iteration: 400, loss: -0.7225430011749268\n",
      "Iteration: 500, loss: -0.7120814323425293\n",
      "Iteration: 600, loss: -0.7201489210128784\n",
      "Iteration: 700, loss: -0.7297685146331787\n",
      "Iteration: 800, loss: -0.7547503709793091\n",
      "Iteration: 900, loss: -0.7578461170196533\n",
      "Iteration: 1000, loss: -0.7571297287940979\n",
      "Iteration: 1100, loss: -0.7597706317901611\n",
      "Iteration: 1200, loss: -0.7467767000198364\n",
      "Iteration: 1300, loss: -0.7615809440612793\n",
      "Iteration: 1400, loss: -0.726969838142395\n",
      "Iteration: 1500, loss: -0.7633358240127563\n",
      "Iteration: 1600, loss: -0.7758433818817139\n",
      "Iteration: 1700, loss: -0.7709601521492004\n",
      "Iteration: 1800, loss: -0.757049560546875\n",
      "Iteration: 1900, loss: -0.7591705322265625\n",
      "Iteration: 2000, loss: -0.7343651652336121\n",
      "Iteration: 2100, loss: -0.7929467558860779\n",
      "Iteration: 2200, loss: -0.7827349901199341\n",
      "Iteration: 2300, loss: -0.780117928981781\n",
      "Iteration: 2400, loss: -0.7754407525062561\n",
      "Iteration: 2500, loss: -0.7490122318267822\n",
      "Iteration: 2600, loss: -0.8145259618759155\n",
      "Iteration: 2700, loss: -0.8152267336845398\n",
      "Iteration: 2800, loss: -0.795110821723938\n",
      "Iteration: 2900, loss: -0.7881788015365601\n",
      "Iteration: 3000, loss: -0.7736793756484985\n",
      "Iteration: 3100, loss: -0.7863227725028992\n",
      "Iteration: 3200, loss: -0.7968019843101501\n",
      "Iteration: 3300, loss: -0.8374592661857605\n",
      "Iteration: 3400, loss: -0.8394869565963745\n",
      "Iteration: 3500, loss: -0.8352574706077576\n",
      "Iteration: 3600, loss: -0.8304911851882935\n",
      "Iteration: 3700, loss: -0.849424421787262\n",
      "Iteration: 3800, loss: -0.7963362336158752\n",
      "Iteration: 3900, loss: -0.7678786516189575\n",
      "Iteration: 4000, loss: -0.8403477072715759\n",
      "Iteration: 4100, loss: -0.8608489036560059\n",
      "Iteration: 4200, loss: -0.8332393765449524\n",
      "Iteration: 4300, loss: -0.8382958769798279\n",
      "Iteration: 4400, loss: -0.8359416723251343\n",
      "Iteration: 4500, loss: -0.8245289325714111\n",
      "Iteration: 4600, loss: -0.8682886958122253\n",
      "Iteration: 4700, loss: -0.8445882797241211\n",
      "Iteration: 4800, loss: -0.8735430240631104\n",
      "Iteration: 4900, loss: -0.8672757744789124\n",
      "Iteration: 5000, loss: -0.8014420866966248\n",
      "Iteration: 5100, loss: -0.8835259675979614\n",
      "Iteration: 5200, loss: -0.8518246412277222\n",
      "Iteration: 5300, loss: -0.8682501316070557\n",
      "Iteration: 5400, loss: -0.8356368541717529\n",
      "Iteration: 5500, loss: -0.8863085508346558\n",
      "Iteration: 5600, loss: -0.8830772638320923\n",
      "Iteration: 5700, loss: -0.8744836449623108\n",
      "Iteration: 5800, loss: -0.8766946196556091\n",
      "Iteration: 5900, loss: -0.7792181372642517\n",
      "Iteration: 6000, loss: -0.8842501044273376\n",
      "Iteration: 6100, loss: -0.9040942788124084\n",
      "Iteration: 6200, loss: -0.8912583589553833\n",
      "Iteration: 6300, loss: -0.9051131010055542\n",
      "Iteration: 6400, loss: -0.9090709686279297\n",
      "Iteration: 6500, loss: -0.8940598964691162\n",
      "Iteration: 6600, loss: -0.8876612782478333\n",
      "Iteration: 6700, loss: -0.882607638835907\n",
      "Iteration: 6800, loss: -0.8148597478866577\n",
      "Iteration: 6900, loss: -0.9051121473312378\n",
      "Iteration: 7000, loss: -0.898862361907959\n",
      "Iteration: 7100, loss: -0.8870229721069336\n",
      "Iteration: 7200, loss: -0.9258966445922852\n",
      "Iteration: 7300, loss: -0.9187694191932678\n",
      "Iteration: 7400, loss: -0.9301072359085083\n",
      "Iteration: 7500, loss: -0.9231386780738831\n",
      "Iteration: 7600, loss: -0.9088920950889587\n",
      "Iteration: 7700, loss: -0.9357907772064209\n",
      "Iteration: 7800, loss: -0.9296779036521912\n",
      "Iteration: 7900, loss: -0.9219752550125122\n",
      "Iteration: 8000, loss: -0.9061833620071411\n",
      "Iteration: 8100, loss: -0.9432464838027954\n",
      "Iteration: 8200, loss: -0.8655775189399719\n",
      "Iteration: 8300, loss: -0.9271208643913269\n",
      "Iteration: 8400, loss: -0.9135544300079346\n",
      "Iteration: 8500, loss: -0.9387837648391724\n",
      "Iteration: 8600, loss: -0.9512065052986145\n",
      "Iteration: 8700, loss: -0.9522279500961304\n",
      "Iteration: 8800, loss: -0.9224250912666321\n",
      "Iteration: 8900, loss: -0.9538922905921936\n",
      "Iteration: 9000, loss: -0.9459570050239563\n",
      "Iteration: 9100, loss: -0.9594871401786804\n",
      "Iteration: 9200, loss: -0.9567359089851379\n",
      "Iteration: 9300, loss: -0.9555273652076721\n",
      "Iteration: 9400, loss: -0.9641516208648682\n",
      "Iteration: 9500, loss: -0.8934441804885864\n",
      "Iteration: 9600, loss: -0.9545367360115051\n",
      "Iteration: 9700, loss: -0.9232311248779297\n",
      "Iteration: 9800, loss: -0.9716941118240356\n",
      "Iteration: 9900, loss: -0.971607506275177\n",
      "Iteration: 10000, loss: -0.9722992777824402\n"
     ]
    }
   ],
   "source": [
    "epochs = 100000\n",
    "epoch_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    log_prob, _, _ = model(data_train.query, data_train.num_total_points,\n",
    "                       data_train.num_context_points, data_train.target_y)\n",
    "    \n",
    "    loss = - log_prob.mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch_counter += 1\n",
    "\n",
    "    if epoch_counter % 1000 == 0:\n",
    "        print('Iteration: {}, loss: {}'.format(epoch_counter, loss))\n",
    "        _, mu, sigma = model(data_test.query, data_test.num_total_points, data_test.num_context_points)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_functions(target_x, target_y, context_x, context_y, pred_y, var)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_y' is not defined"
     ]
    }
   ],
   "source": [
    "plot_functions(target_x, target_y, context_x, context_y, pred_y, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "\n",
    "  for it in range(TRAINING_ITERATIONS):\n",
    "    sess.run([train_step])\n",
    "\n",
    "    # Plot the predictions in `PLOT_AFTER` intervals\n",
    "    if it % PLOT_AFTER == 0:\n",
    "      loss_value, pred_y, var, target_y, whole_query = sess.run(\n",
    "          [loss, mu, sigma, data_test.target_y, data_test.query])\n",
    "\n",
    "      (context_x, context_y), target_x = whole_query\n",
    "      print('Iteration: {}, loss: {}'.format(it, loss_value))\n",
    "\n",
    "      # Plot the prediction and the context\n",
    "      plot_functions(target_x, target_y, context_x, context_y, pred_y, var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
